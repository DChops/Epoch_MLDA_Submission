{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depression_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPlXXGZ0mY2"
      },
      "source": [
        "### Importing required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaientgUxFq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45febc45-0194-4fc2-9948-23228a3c9b45"
      },
      "source": [
        "!pip install sktime"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sktime in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.37.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.13.0)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.54.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
            "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime) (0.37.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.0.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7p47XDDyQ8z"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sktime.transformations.panel.rocket import Rocket"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOkY6Pdw0uiK"
      },
      "source": [
        "### Data Cleaning \n",
        "After setting the timestamps to index, we combined the 55 datasets to facilitate the process of feeding it into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4CzrHVCxf2R"
      },
      "source": [
        "condition = {a: pd.read_csv(\"condition_{x}.csv\".format(x = str(a))) for a in range(1, 24)}\n",
        "control = {b+23: pd.read_csv(\"control_{x}.csv\".format(x = str(b))) for b in range(1, 33)}"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zrlo4G1y7sX"
      },
      "source": [
        "for i in range(1, 24):\n",
        "    condition[i].drop(columns = 'date', inplace = True)\n",
        "    condition[i][\"timestamp\"] = pd.to_datetime(condition[i][\"timestamp\"])\n",
        "    condition[i] = condition[i].set_index('timestamp')\n",
        "    \n",
        "for j in range(24, 56):\n",
        "    control[j].drop(columns = 'date', inplace = True)\n",
        "    control[j][\"timestamp\"] = pd.to_datetime(control[j][\"timestamp\"])\n",
        "    control[j] = control[j].set_index('timestamp')    "
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ncx6hyiATrk",
        "outputId": "366765ba-0b21-4ccf-cf66-5486cf3c079a"
      },
      "source": [
        "for i in range(1, 24):\n",
        "    index = 0\n",
        "    for j in condition[i]['activity']:\n",
        "        if(j==0):\n",
        "            index += 1\n",
        "        else:\n",
        "            break       \n",
        "    print(index)\n",
        "    condition[i] = condition[i][index:]\n",
        "#Removing the zeros at the start    "
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "25\n",
            "101\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "3\n",
            "5\n",
            "24\n",
            "27\n",
            "1\n",
            "22\n",
            "38\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxY7kbhvAXBF",
        "outputId": "562e9ac4-d212-47ab-f470-ce3faae0a230"
      },
      "source": [
        "for i in range(24, 56):\n",
        "    index = 0\n",
        "    for j in control[i]['activity']:\n",
        "        if(j==0):\n",
        "            index += 1\n",
        "        else:\n",
        "            break       \n",
        "    print(index)\n",
        "    control[i] = control[i][index:]\n",
        "#Removing the zeros at the start    "
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "22\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "40\n",
            "40\n",
            "0\n",
            "67\n",
            "16\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHChAm7jy79n"
      },
      "source": [
        "condition.update(control)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QBkAg-Z16Tr"
      },
      "source": [
        "Slicing the arrays so that they can be combined smoothly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK9H9Ya71efS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b1c9d1-612e-4ebf-e12c-96400d814104"
      },
      "source": [
        "array=[np.array(condition[x]['activity'][:19299]) for x in range(1,56)]\n",
        "lengths=[len(x) for x in array]\n",
        "max(lengths)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19299"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "qaNjE9z51Le8",
        "outputId": "d9c9aa0f-228c-427c-b24f-d9ffdfc7d1fc"
      },
      "source": [
        "z=pd.DataFrame()\n",
        "z['x']=array\n",
        "print(z.shape)\n",
        "z.head()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[143, 0, 20, 166, 160, 17, 646, 978, 306, 277,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1468, 1006, 468, 306, 143, 205, 410, 349, 566...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[7, 8, 7, 8, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[510, 637, 598, 251, 93, 180, 199, 526, 251, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 2, 127, 161, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   x\n",
              "0  [143, 0, 20, 166, 160, 17, 646, 978, 306, 277,...\n",
              "1  [1468, 1006, 468, 306, 143, 205, 410, 349, 566...\n",
              "2  [7, 8, 7, 8, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, ...\n",
              "3  [510, 637, 598, 251, 93, 180, 199, 526, 251, 5...\n",
              "4  [2, 2, 127, 161, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,..."
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DesT-1ye1C0G"
      },
      "source": [
        "X=z\n",
        "y=[]\n",
        "from sklearn.model_selection import train_test_split\n",
        "for i in range(23):\n",
        "  y.append(1)\n",
        "for i in range(32):\n",
        "  y.append(0)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz9e4BWm29jd"
      },
      "source": [
        "### Training the Model\n",
        "Finally, the moment we've all been waiting for, we use the ROCKET model on the timeseries to extract the features. The new datasets are fed into a Rigid Classifier to classify them as Depressed (1) or not (0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg4Td7Iszwfq",
        "outputId": "98a2b171-3dfd-419d-81ee-88c0c50555bf"
      },
      "source": [
        "rocket = Rocket(num_kernels=100, random_state=111) \n",
        "rocket.fit(X_train)\n",
        "X_train_transform = rocket.transform(X_train)\n",
        "X_train_transform.shape"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3zcJoD1888r",
        "outputId": "07e609c4-b8db-475f-cf39-9084ed32c81b"
      },
      "source": [
        "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "classifier.fit(X_train_transform, y_train)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
              "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
              "       2.15443469e+02, 1.00000000e+03]),\n",
              "                  normalize=True)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu7MB-UD9Ae7",
        "outputId": "83a5633e-10eb-4e09-8aaf-b00ec3851b2e"
      },
      "source": [
        "X_test_transform = rocket.transform(X_test)\n",
        "classifier.score(X_test_transform,y_test)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5IDN3qfGp_A"
      },
      "source": [
        "y_test\n",
        "y_pred=classifier.predict(X_test_transform)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtWhkmRI3ebH"
      },
      "source": [
        "### Testing the model validity with K-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvwBYpPJlfV"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=11,shuffle=True)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRz1f08ULcda",
        "outputId": "a98ea30d-b034-415b-b29b-df70e3e4f320"
      },
      "source": [
        "y_2=pd.DataFrame(y)\n",
        "accuracies=[]\n",
        "for train_index, test_index in kfold.split(X):\n",
        "  # splitting\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "    y_train, y_test = y_2.loc[train_index], y_2.loc[test_index]\n",
        "\n",
        "    # rocket transformation\n",
        "    rocket = Rocket(num_kernels=100, random_state=111) \n",
        "    rocket.fit(X_train)\n",
        "    X_train_transform = rocket.transform(X_train)\n",
        "    print(X_train_transform.shape)\n",
        "\n",
        "    # classifier\n",
        "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "    classifier.fit(X_train_transform, y_train[0])\n",
        "    X_test_transform = rocket.transform(X_test)\n",
        "    ac=classifier.score(X_test_transform,y_test[0])\n",
        "    print(ac)\n",
        "    accuracies.append(ac)\n"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 12 13 14 15 16 17 18 19 20 22 23 24 25 26\n",
            " 27 28 29 30 31 32 33 34 35 36 37 38 39 41 42 43 44 46 47 48 49 50 51 52\n",
            " 53 54] TEST: [10 11 21 40 45]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n",
            "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26 27 28 29 32 33 34 35 37 38 39 40 41 42 43 45 46 47 48 49 50 51 52\n",
            " 53 54] TEST: [13 30 31 36 44]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 16 17 18 19 20 21 22 23 24 25 26\n",
            " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 49 51 52\n",
            " 53 54] TEST: [ 8 14 15 47 50]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n",
            "TRAIN: [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 17 18 20 21 22 23 24 25 26 27\n",
            " 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48 49 50 51 52\n",
            " 53 54] TEST: [ 0  7 16 19 41]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 27 28 30 31 32 33 34 35 36 37 38 39 40 41 42 44 45 46 47 48 49 50 51 52\n",
            " 53 54] TEST: [24 25 26 29 43]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n",
            "TRAIN: [ 0  1  2  5  6  7  8  9 10 11 12 13 14 15 16 17 19 21 22 23 24 25 26 27\n",
            " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 50 51 52\n",
            " 53 54] TEST: [ 3  4 18 20 49]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 13 14 15 16 18 19 20 21 22 23 24 25 26\n",
            " 27 28 29 30 31 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 52\n",
            " 53 54] TEST: [ 5 12 17 32 39]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n",
            "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23 24\n",
            " 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 49 50\n",
            " 52 54] TEST: [22 28 48 51 53]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 34 36 38 39 40 41 43 44 45 46 47 48 49 50 51\n",
            " 53 54] TEST: [33 35 37 42 52]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n",
            "TRAIN: [ 0  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
            " 26 27 28 29 30 31 32 33 35 36 37 38 39 40 41 42 43 44 45 47 48 49 50 51\n",
            " 52 53] TEST: [ 1  9 34 46 54]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n",
            "TRAIN: [ 0  1  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24 25 26\n",
            " 28 29 30 31 32 33 34 35 36 37 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n",
            " 53 54] TEST: [ 2  6 23 27 38]\n",
            "(50, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGM3PWOVDWn7",
        "outputId": "35372566-bdc2-4676-bfe0-b8bfdd686cee"
      },
      "source": [
        "df = pd.DataFrame(accuracies)\n",
        "df.value_counts()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    4\n",
              "0.8    3\n",
              "0.6    2\n",
              "0.4    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfVW8V1KVxTU",
        "outputId": "7351bbe6-814f-4cf4-f15a-8371972f594d"
      },
      "source": [
        "df = pd.DataFrame(accuracies)\n",
        "df.mean()"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.763636\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3o-u_H4NobG"
      },
      "source": [
        "### Hyperparameter Tuning\n",
        "\n",
        "We have hypertuned the model using GridSearchCV with 5 fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKlmyW6tQf15",
        "outputId": "a4e115b4-e9ba-4ade-d4e4-3a9030eaea5b"
      },
      "source": [
        "nums = np.arange(100,1001,100)\n",
        "scores = []\n",
        "for i in nums:\n",
        "  # Create and train a new model instance.\n",
        "  rocket = Rocket(num_kernels= i, random_state=111) \n",
        "  rocket.fit(X_train)\n",
        "\n",
        "  X_train_transform = rocket.transform(X_train)\n",
        "  # X_train_transform.shape\n",
        "\n",
        "  classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "  classifier.fit(X_train_transform, y_train)\n",
        "\n",
        "  X_test_transform = rocket.transform(X_test)\n",
        "  score = classifier.score(X_test_transform,y_test)\n",
        "  scores.append(score)\n",
        "  print(score)\n"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-FDf3e8RhQo",
        "outputId": "0ef15824-edeb-4172-f4fb-808c0c846c6d"
      },
      "source": [
        "scores"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 0.4, 0.4, 0.6, 0.4, 0.4, 0.6, 0.4, 0.6, 0.6]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd9W_SMpRvmu"
      },
      "source": [
        "As we can see the optimal parameter is num_kernels = 100, with the an accuracy of 0.8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtUVyFZk38EE"
      },
      "source": [
        "### Saving the Model for Deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KJ0D_OJmiyh",
        "outputId": "b95cd8cb-8dfd-4bf4-8fce-93ba3832808e"
      },
      "source": [
        "# Create and train a new model instance.\n",
        "rocket = Rocket(num_kernels=100, random_state=111) \n",
        "rocket.fit(X_train)\n",
        "\n",
        "X_train_transform = rocket.transform(X_train)\n",
        "X_train_transform.shape\n",
        "\n",
        "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "classifier.fit(X_train_transform, y_train)\n",
        "\n",
        "X_test_transform = rocket.transform(X_test)\n",
        "print(classifier.score(X_test_transform,y_test))"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:2334: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2_jpmu-xY9r"
      },
      "source": [
        "from pickle import dump\n",
        "# save the model\n",
        "dump(rocket, open('rocket_new.pkl', 'wb'))\n",
        "dump(classifier, open('classifier_new.pkl', 'wb'))"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mMZ1EoPXNua"
      },
      "source": [
        "### Extra Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOs6mrHzXNBB"
      },
      "source": [
        "from sktime.classification.dictionary_based import ContractableBOSS"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jKK_JpnXU1m",
        "outputId": "94bff10f-cb77-4c2c-b5bc-0cb2d138832a"
      },
      "source": [
        "Shape = ContractableBOSS()\n",
        "Shape.fit(X_train,y_train[0])\n",
        "\n",
        "Shape.score(X_test,y_test)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Xhmt3cZgGD"
      },
      "source": [
        "from sktime.classification.interval_based import RandomIntervalSpectralForest"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdDvR0HjXisv",
        "outputId": "73c9a7d6-4aad-44bc-b2c4-c46a25bdfdc9"
      },
      "source": [
        "nums = np.arange(100,501,50)\n",
        "scores = []\n",
        "for i in nums:\n",
        "  # Create and train a new model instance.\n",
        "  Rise = RandomIntervalSpectralForest(n_estimators = i)\n",
        "  Rise.fit(X_train,y_train[0]) \n",
        "\n",
        "  score = Rise.score(X_test,y_test)\n",
        "  scores.append(score)\n",
        "  print(score)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n",
            "0.6\n",
            "0.6\n",
            "0.6\n",
            "0.6\n",
            "0.6\n",
            "0.6\n",
            "0.6\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7sgTGzbZTsb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
